# Algorithmic Problem Solving, Spring 2024, Lecture 9
# String Algorithms

![image](https://github.itu.dk/storage/user/716/files/48bae272-6ecb-43e5-b574-0f73e417ed58)


---

## Outline 

- Administrative
- Tries
- String hashing with applications

---

## Outlook

- reminder: if you missed assignment 4 or didn't get it approved, submit by next week, April 10, 13:59.
- next week: last lecture, project phase starts
- we will send out a questionnaire and help you with group finding
- Project phase: 
  - Weekly meetings with supervisors (Riko/Martin/Alexander/Simon) 14:00-16:00 slot
  - 16:00-18:00 TAs are in the exercise room to help out
- Mandatory assignments:
  - if you missed an assignment, re-do chances are going to be available starting in two weeks

---

## String algorithms

**Notation**: We think about a string `x` of `n` characters as a sequence `x[0], x[1], ..., x[n-1]`. 

**OBS**: In your favorite programming language, string are probably _immutable_,
so every time you make a change to a string the old string is copied. Thus operations such as `s += '\n'` are really expensive (linear in the size of the string).

## String algorithms that you know

- Tries
- Longest Common Subsequence
- KMP?
- Anything else?

---

## Tries

Tries provide a compact representation of a set of strings. 
Each trie node represents a prefix of one (or more) strings in the set. 

**Example problem:** <https://open.kattis.com/problems/bing>

---

### Data Structure

We aim for a data structure that has a size in the order of the sum of the lengths of the strings in the set. 
If the universe is small, like `a-z` or `A-z`, we can associate with each node an array of 26 (52) children. 
If the universe is large, we usually store the children as a hashmap mapping a character to a node.

---

Code example:
```python
class Trie:
    # A trie for lower-case characters a-z
    def __init__(self):
        self.root = Node()

    def insert(self, s):
        node = self.root
        for i, c in enumerate(s):
            if not node.children[ord(c) - ord('a')]:
                # let the node create the subtree
                node = node.create(s, i)
                break
            node = node.children[ord(c) - ord('a')]


class Node:
    def __init__(self):
        self.children = [None] * 26

    def create(self, s, index):
        node = self
        for i in range(index, len(s)):
            n = Node()
            node.children[ord(s[i]) - ord('a')] = n
            node = n
        return node

```

## Analysis 

If we insert strings $s_1, \ldots, s_n$ of length $\ell_1, \ldots, \ell_n$ into an initially empty trie, the running time is bound by $O\left(\sum_{1 \leq i \leq n} \ell_i\right)$. This means it is linear in the size of the input. We can search for a string in the trie in time linear in the length of the string.

### Discussion: 
1. How do we solve <https://open.kattis.com/problems/bing>?
2. How to approach <https://open.kattis.com/problems/autocorrect>?

---
## String hashing

Lecture problem: <https://open.kattis.com/problems/dvaput>

Let `x` be a string of length `n`. Let `m <= n`. **Claim.** If we can check for a repeating _substring_ (a subsequence that is consecutive) of length `m` in time `O(n)`, then we can find the longest repeated substring in time `O(n log n)`. **HOW?**

String hashing allows us to design an algorithm that outputs `True` or `False` (depending on whether a repeated pattern of length `m` exists) with the following guarantee:
- If there is a repeated pattern of length `m`, the algorithm always returns `True`.
- If there is no repeated pattern of length `m`, the algorithm will _very likely_ return `False`. (More details below.)
```python
import random

p = 2**63 - 1 # choose a large prime number 
# the coefficients should be chosen at random, but pypy is much faster with small coefficients.
a = 26 #random.randint(0, p-1) 

def repeated_string(x, m):
    found = set() # all the hashcodes we have seen
    h = 0
    multiplier = 1

    # compute hash of x[0],..., x[m - 1]
    for i in range(m):
        h = (h * a + ord(x[i])) % p
        multiplier = (multiplier * a) % p

    found.add(h)

    # rolling hash over remaining string
    for i in range(1, n - m):
        h = (h * a - (ord(x[i-1]) * multiplier) % p) % p
        h = (h + ord(x[i + m - 1])) % p

        if h in found:
            return True
        found.add(h)
    return False
```

## Idea 

The idea is to use a large prime number `p` (for example the Mersenne prime `2^63 - 1`). For a string `x` of length `m`, we define the polynomial 

$P_x(a) = (x[0] \cdot a^{m - 1} + x[1] \cdot a^{m - 2} + ... + x[m-1] \cdot a^{0}) \mod p$, where $a$ is a number from $\{1, ..., p - 1\}$.

Evaluating this polynomial is the hash value of the string `x`.

- Fast evaluation: Computing `a^... mod p` can be time-consuming. A better way is to compute it piece by piece using the recursive formulation:
  - `h[0] = x[0]`
  - `h[k] = (h[k - 1] * a + x[k - 1]) mod p`
- Updating the hash: Let's say we have the hash value `h` for `x[0],...,x[m - 1]`, and want to update it to the hash value for `x[1],...,x[m]`.  This can be achieved by computing 
   - `h = (h - x[0] * a^{m - 1}) mod p`
   - `h = (a * h + x[m]) mod p`

In this way, we spent `O(1)` time for recomputing the hash value. (Assuming that we precomputed the value `a^(m - 1) mod p`.)
To find a repeated substring of length `m` in a string of length `n`, we keep a rolling hash of the length-`m` substrings. As soon as we find a duplicated hash code, we claim that the string contains a repeated substring of length `m`.  The time spent is `O(n + m)`. 

## Analysis

Indeed, if the string contains a repeated substring of length `m`, we are certain to notice it. However, if there is no such substring, it could happen that `P_x(a) = P_y(a)` for two substrings `x` and `y` that are different. How likely is this to happen? We can write `D(a) = P_x(a) - P_y(a) = ((x[0] - y[0]) * a^{m - 1} + ... + x[m - 1] - y[m-1]) mod p`. Since `x` and `y` are different, `D(a)` is not the zero polynomial and has degree `m`. The [fundamental theorem of algebra](https://en.wikipedia.org/wiki/Fundamental_theorem_of_algebra) says that there are at most `m` values for `a` such that `D(a)` is 0, that is, the hash values are the same. Since there are `p` choices for `a`, basic probability theory says that the probability that `x` and `y` have the same hash value is at most `m/p`. In our case, we have `m` at most 200,000, and we can choose `p` to be a large prime number, for example the Mersenne prime `p = 2^63 - 1`. The probability for two different strings to collide is then not more than ~ `2^{-45}`.

In our setting, we can think about comparing all substrings of length `m` to each other. A phenomenon called the [`Birthday paradox`](https://en.wikipedia.org/wiki/Birthday_problem) says that we will notice collisions much earlier than what we would usually assume. In our setting, there are roughly `(n - m)^2/2` pairs of substrings of length `m`. The probability that none of them collides is then at least `(1 - m/p)^{(n - m)^2/2}`. For example, this bound for `m=n/2` says that there is a chance of at most 0.01% to see a collision between two different substrings of length `n/2` (for `n=200,000` and `p=2^63-1`, as discussed above). If we had used the Mersenne prime `p=2^31-1`, the collision probability of two strings is `~2^-14` (tiny), but the above calculation makes it almost certain to see a hash collision if we compare all pairs.

### Why using a Mersenne prime?

A Mersenne prime has the advantage that the modulo operation can be carried out extremely efficient. If `p = 2^q - 1`, then computing  `y = x mod p` boils down to:

```python
y = (x & p) + (x >> q)
if (y >= p): y -= p
```

### Solving Dvaput in Python

(Edit: This discussion is outdated, it was valid for the <= 2022 editions of the course. It did work with $p=2^{63} - 1$ and a random choice of $a$. ðŸ¥³ It is maybe still of interest.)


Although using `pypy` instead of `python` (as default on the kattis servers) provides a large speed-up for integer operations, I could not get it to work for `p = 2^63 - 1`. Instead, I asked Wolfram alpha for a smaller prime <https://www.wolframalpha.com/input?i=16+digit+prime> and used that one instead. For small values of `a` below 256, my code was fast enough to pass the time limit. This is probably because `pypy` will carry out the integer arithmetic more efficiently since all multiplications are guaranteed to fit into 64 bits.

---

# Curated problem list

<details><summary>bing</summary> <p>the lecture problem, solve with tries. (Maybe a HashMap of prefixes is fast enough?)</p></details>
<details><summary>quiteaproblem/exam</summary> <p>Try adhoc solution. to show that you understood dynamic programming, try to formulate it as DP. (Even though it's overkill here.)</p></details>
<details><summary>heritage</summary> <p>Try DP. Might be difficult to come up with the subproblem.</p></details>
<details><summary>buzzwords</summary><p>Variant of Longest Repeating Subsequence, might also be solvable with other data structures since input seems to be small</p></details>
<details><summary>autocorrect</summary><p>Somewhat difficult trie task</p></details>











